<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Deng-Ping Fan&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ethz2.png">
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Deng-Ping Fan</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:25px">
      <table>
        <tbody>
          <tr>
            <td width="670">
              <div id="toptitle">
                <h1>Deng-Ping Fan &nbsp;</h1>
              </div>
              <p>
                I am a postdoc, working with <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Prof. Luc Van Gool</a> in <a href="https://vision.ee.ethz.ch/">Computer Vision Lab</a> @ <a href="https://ethz.ch/en.html">ETH Zurich</a>.
                Under the supervision of <a href="https://mmcheng.net/cmm/">Prof. Ming-Ming Cheng</a>, I obtained my bachelor's degree and my doctoral degree from Nankai University in 2016 and 2020, respectively.
                My research interests include computer vision and machine learning (especially deep learning).
              </p>
              <h3 style="padding-top:-5px"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:dengpfan@gmail.com">dengpfan@gmail.com</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=UB3doCoAAAAJ" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/yun-liu" target="_blank">Github</a>
            </td>
            <td>
              <img src="./images/love2.jpg" border="0" width="200">
            </td>
          </tr>
        </tbody>
      </table>

      <!-- Journal papers -->
      <h2> Journal Publications</h2>
      <ul>
        <li>
          <p>
            <b>MobileSal: Extremely Efficient RGB-D Salient Object Detection</b><br>
            Yu-Huan Wu, <strong>Yun Liu</strong>, Jun Xu, Jia-Wang Bian, Yuchao Gu, Ming-Ming Cheng<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2021)MobileSal%20-%20Extremely%20Efficient%20RGB-D%20Salient%20Object%20Detection.pdf">[PDF]</a>
            <a href="https://mmcheng.net/mobilesal/">[Project Page]</a>
            <a href="https://github.com/yuhuan-wu/MobileSal">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9647954">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Semantic Edge Detection with Diverse Deep Supervision</b><br>
            <strong>Yun Liu</strong>, Ming-Ming Cheng, Deng-Ping Fan, Le Zhang, Jia-Wang Bian, and Dacheng Tao<br>
            <i>International Journal of Computer Vision (IJCV)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(IJCV'2021)Semantic%20Edge%20Detection%20with%20Diverse%20Deep%20Supervision.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/DDS">[Code]</a>
            <a href="https://link.springer.com/article/10.1007/s11263-021-01539-8">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>SAMNet: Stereoscopically Attentive Multi-scale Network for Lightweight Salient Object Detection</b><br>
            <strong>Yun Liu<sup>#</sup></strong>, Xin-Yu Zhang<sup>#</sup>, Jia-Wang Bian, Le Zhang, and Ming-Ming Cheng<br>
            <i>IEEE Transactions on Image Processing (TIP)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(TIP'2021)SAMNet%20-%20Stereoscopically%20Attentive%20Multi-scale%20Network%20for%20Lightweight%20Salient%20Object%20Detection.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/FastSaliency">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9381668">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Regularized Densely-connected Pyramid Network for Salient Instance Segmentation</b><br>
            Yu-Huan Wu, <strong>Yun Liu</strong>, Le Zhang, Wang Gao, and Ming-Ming Cheng<br>
            <i>IEEE Transactions on Image Processing (TIP)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(TIP'2021)Regularized%20Densely-connected%20Pyramid%20Network%20for%20Salient%20Instance%20Segmentation.pdf">[PDF]</a>
            <a href="https://github.com/yuhuan-wu/RDPNet">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9382868">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>DNA: Deeply-supervised Nonlinear Aggregation for Salient Object Detection</b><br>
            <strong>Yun Liu</strong>, Ming-Ming Cheng, Xin-Yu Zhang, Guang-Yu Nie, and Meng Wang<br>
            <i>IEEE Transactions on Cybernetics (TCYB)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(TCYB'2021)DNA%20-%20Deeply-supervised%20Nonlinear%20Aggregation%20for%20Salient%20Object%20Detection.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/DNA">[Saliency Maps]</a>
            <a href="https://ieeexplore.ieee.org/document/9345433">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Lightweight Salient Object Detection via Hierarchical Visual Perception Learning</b><br>
            <strong>Yun Liu<sup>#</sup></strong>, Yu-Chao Gu<sup>#</sup>, Xin-Yu Zhang<sup>#</sup>, Weiwei Wang, and Ming-Ming Cheng<br>
            <i>IEEE Transactions on Cybernetics (TCYB)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(TCYB'2020)Lightweight%20Salient%20Object%20Detection%20via%20Hierarchical%20Visual%20Perception%20Learning.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/FastSaliency">[Code]</a>
            <a href="https://yun-liu.github.io/materials/TCYB2020_HVPNet_Chinese_Version.pdf">[中译版]</a>
            <a href="https://ieeexplore.ieee.org/document/9285193">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Leveraging Instance-, Image- and Dataset-Level Information for Weakly Supervised Instance Segmentation</b><br>
            <strong>Yun Liu<sup>#</sup></strong>, Yu-Huan Wu<sup>#</sup>, Peisong Wen, Yujun Shi, Yu Qiu, and Ming-Ming Cheng<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2020)Leveraging%20Instance-%2C%20Image-%20and%20Dataset-Level%20Information%20for%20Weakly%20Supervised%20Instance%20Segmentation.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/LIID">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9193980">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>MS-TCN++: Multi-Stage Temporal Convolutional Network for Action Segmentation</b><br>
            Shijie Li, Yazan Abu Farha, <strong>Yun Liu</strong>, Ming-Ming Cheng, and Juergen Gall<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2020)MS-TCN%2B%2B%20-%20Multi-Stage%20Temporal%20Convolutional%20Network%20for%20Action%20Segmentation.pdf">[PDF]</a>
            <a href="https://mmcheng.net/ms-tcn/">[Project Page]</a>
            <a href="https://github.com/sj-li/MS-TCN2">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9186840">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Ordered or Orderless: A Revisit for Video based Person Re-Identification</b><br>
            Le Zhang, Zenglin Shi, Joey Tianyi Zhou, Ming-Ming Cheng, <strong>Yun Liu</strong>, Jia-Wang Bian, Zeng Zeng, and Chunhua Shen<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2020)Ordered%20or%20Orderless%20-%20A%20Revisit%20for%20Video%20based%20Person%20Re-Identification.pdf">[PDF]</a>
            <a href="https://github.com/ZhangLeUestc/VideoReid-TPAMI2020">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9018082">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence</b><br>
            Jia-Wang Bian, Wen-Yan Lin, <strong>Yun Liu</strong>, Le Zhang, Sai-Kit Yeung, Ming-Ming Cheng, and Ian Reid<br>
            <i>International Journal of Computer Vision (IJCV)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(IJCV'2020)GMS%20-%20Grid-based%20Motion%20Statistics%20for%20Fast%2C%20Ultra-robust%20Feature%20Correspondence.pdf">[PDF]</a>
            <a href="http://jwbian.net/gms">[Project Page]</a>
            <a href="https://github.com/JiawangBian/GMS-Feature-Matcher">[Code]</a>
            <a href="https://yun-liu.github.io/materials/IJCV2020_GMS_Video.mp4">[Video]</a>
            <a href="https://link.springer.com/article/10.1007%2Fs11263-019-01280-3">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Richer Convolutional Features for Edge Detection</b><br>
            <strong>Yun Liu</strong>, Ming-Ming Cheng, Xiaowei Hu, Jia-Wang Bian, Le Zhang, Xiang Bai, and Jinhui Tang<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2019<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2019)Richer%20Convolutional%20Features%20for%20Edge%20Detection.pdf">[PDF]</a>
            <a href="https://mmcheng.net/rcfedge/">[Project Page]</a>
            <a href="https://github.com/yun-liu/rcf">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/8516362">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Nonlinear Regression via Deep Negative Correlation Learning</b><br>
            Le Zhang, Zenglin Shi, Ming-Ming Cheng, <strong>Yun Liu</strong>, Jia-Wang Bian, Joey Tianyi Zhou, Guoyan Zheng, and Zeng Zeng<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2019<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2019)Nonlinear%20Regression%20via%20Deep%20Negative%20Correlation%20Learning.pdf">[PDF]</a>
            <a href="https://mmcheng.net/dncl/">[Project Page]</a>
            <a href="https://github.com/shizenglin/Deep-NCL">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/8850209">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>BING: Binarized Normed Gradients for Objectness Estimation at 300fps</b><br>
            Ming-Ming Cheng<sup>#</sup>, <strong>Yun Liu<sup>#</sup></strong>, Wen-Yan Lin, Ziming Zhang,  Paul L. Rosin, and Philip Torr<br>
            <i>Computational Visual Media (CVMJ)</i>, 2019<br>
            <a href="https://yun-liu.github.io/papers/(CVM'2019)BING%20-%20Binarized%20Normed%20Gradients%20for%20Objectness%20Estimation%20at%20300fps.pdf">[PDF]</a>
            <a href="https://mmcheng.net/zh/bing/">[Project Page]</a>
            <a href="https://github.com/yun-liu/bing">[Code]</a>
            <a href="https://link.springer.com/article/10.1007/s41095-018-0120-1">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Sequential Optimization for Efficient High-Quality Object Proposal Generation</b><br>
            Ziming Zhang, <strong>Yun Liu</strong>, Xi Chen, Yanjun Zhu, Ming-Ming Cheng, Venkatesh Saligrama, and Philip H.S. Torr<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2017<br>
            <a href="https://yun-liu.github.io/papers/(TPAMI'2017)Sequential%20Optimization%20for%20Efficient%20High-Quality%20Object%20Proposal%20Generation.pdf">[PDF]</a>
            <!-- <a href="https://pan.baidu.com/s/1slEK7Q9?errno=0&errmsg=Auth%20Login%20Sucess&&bduss=&ssnerror=0">[Code]</a> -->
            <a href="https://github.com/Zhang-VISLab/Sequential-Optimization-for-Efficient-High-Quality-Object-Proposal-Generation">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/7932893">[Official Version]</a>
          </p>
        </li>
      </ul>

      <!-- conference papers -->
      <h2> Conference Publications </h2>
      <ul>
        <li>
          <p>
            <b>DOTS: Decoupling Operation and Topology in Differentiable Architecture Search</b><br>
            Yuchao Gu, Lijuan Wang, <strong>Yun Liu</strong>, Yi Yang, Yu-Huan Wu, Shao-Ping Lu, and Ming-Ming Cheng<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(CVPR'2021)DOTS%20-%20Decoupling%20Operation%20and%20Topology%20in%20Differentiable%20Architecture%20Search.pdf">[PDF]</a>
            <a href="https://yun-liu.github.io/materials/CVPR2021_DOTS_Supplementary.pdf">[Supplementary Material]</a>
            <a href="https://github.com/guyuchao/DOTS">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Gu_DOTS_Decoupling_Operation_and_Topology_in_Differentiable_Architecture_Search_CVPR_2021_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>MiniSeg: An Extremely Minimum Network for Efficient COVID-19 Segmentation</b><br>
            Yu Qiu, <strong>Yun Liu*</strong>, Shijie Li, and Jing Xu*<br>
            <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2021<br>
            <a href="https://yun-liu.github.io/papers/(AAAI'2021)MiniSeg%20-%20An%20Extremely%20Minimum%20Network%20for%20Efficient%20COVID-19%20Segmentation.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/MiniSeg">[Code]</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/16617">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Rethinking Computer-aided Tuberculosis Diagnosis</b><br>
            <strong>Yun Liu<sup>#</sup></strong>, Yu-Huan Wu<sup>#</sup>, Yunfeng Ban, Huifang Wang, and Ming-Ming Cheng<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR, <strong>Oral</strong>)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(CVPR'2020)Rethinking%20Computer-aided%20Tuberculosis%20Diagnosis.pdf">[PDF]</a>
            <a href="https://mmcheng.net/tb/">[Project Page]</a>
            <a href="https://drive.google.com/file/d/1r-oNYTPiPCOUzSjChjCIYTdkjBTugqxR/view?usp=sharing">[Dataset on Google Drive]</a>
            <a href="https://pan.baidu.com/s/1INhqaZyPFKWPFXgynerXew">[Dataset on Baidu Yunpan]</a>
            <a href="https://competitions.codalab.org/competitions/25848">[<strong>Online Challenge</strong>]</a>
            <a href="https://yun-liu.github.io/materials/CVPR2020_TB_Oral_Video.mp4">[Video]</a>
            <a href="https://yun-liu.github.io/materials/CVPR2020_TB_PPT.pdf">[PPT]</a>
            <a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Rethinking_Computer-Aided_Tuberculosis_Diagnosis_CVPR_2020_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Pyramid Constrained Self-Attention Network for Fast Video Salient Object Detection</b><br>
            Yuchao Gu, Lijuan Wang, Ziqin Wang, <strong>Yun Liu</strong>, Ming-Ming Cheng, and Shao-Ping Lu<br>
            <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2020<br>
            <a href="https://yun-liu.github.io/papers/(AAAI'2020)Pyramid%20Constrained%20Self-Attention%20Network%20for%20Fast%20Video%20Salient%20Object%20Detection.pdf">[PDF]</a>
            <a href="http://mmcheng.net/pcsa/">[Project Page]</a>
            <a href="https://github.com/guyuchao/PyramidCSA">[Code]</a>
            <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6718">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Scoot: A Perceptual Metric for Facial Sketches</b><br>
            Deng-Ping Fan, ShengChuan Zhang, Yu-Huan Wu, <strong>Yun Liu</strong>, Ming-Ming Cheng, Bo Ren, Paul Rosin, and Rongrong Ji<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2019<br>
            <a href="https://yun-liu.github.io/papers/(ICCV'2019)Scoot%20-%20A%20Perceptual%20Metric%20for%20Facial%20Sketches.pdf">[PDF]</a>
            <a href="http://dpfan.net/Scoot/">[Project Page]</a>
            <a href="https://yun-liu.github.io/materials/ICCV2019_Scoot_Supplementary.pdf">[Supplementary Material]</a>
            <a href="https://github.com/DengPingFan/Scoot">[Code]</a>
            <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Fan_Scoot_A_Perceptual_Metric_for_Facial_Sketches_ICCV_2019_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Multi-Level Context Ultra-Aggregation for Stereo Matching</b><br>
            Guang-Yu Nie, Ming-Ming Cheng, <strong>Yun Liu</strong>, Zhengfa Liang, Deng-Ping Fan, Yue Liu, and Yongtian Wang<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019<br>
            <a href="https://yun-liu.github.io/papers/(CVPR'2019)Multi-Level%20Context%20Ultra-Aggregation%20for%20Stereo%20Matching.pdf">[PDF]</a>
            <a href="https://mmcheng.net/mcua/">[Project Page]</a>
            <a href="https://yun-liu.github.io/materials/CVPR2019_MCUA_Supplementary.pdf">[Supplementary Material]</a>
            <a href="https://yun-liu.github.io/materials/CVPR2019_MCUA_PPT.pdf">[PPT]</a>
            <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Nie_Multi-Level_Context_Ultra-Aggregation_for_Stereo_Matching_CVPR_2019_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Structured Skip List: A Compact Data Structure for 3D Reconstruction</b><br>
            Shi-Jie Li, Ming-Ming Cheng, <strong>Yun Liu</strong>, Shao-Ping Lu, Yahui Wang, and Victor Prisacariu<br>
            <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2018<br>
            <a href="https://yun-liu.github.io/papers/(IROS'2018)Structured%20Skip%20List%20-%20A%20Compact%20Data%20Structure%20for%203D%20Reconstruction.pdf">[PDF]</a>
            <a href="https://ieeexplore.ieee.org/document/8594075">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>DEL: Deep Embedding Learning for Efficient Image Segmentation</b><br>
            <strong>Yun Liu</strong>, Peng-Tao Jiang, Vahan Petrosyan, Shi-Jie Li, Jiawang Bian, Le Zhang, and Ming-Ming Cheng<br>
            <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2018<br>
            <a href="https://yun-liu.github.io/papers/(IJCAI'2018)DEL%20-%20Deep%20Embedding%20Learning%20for%20Efficient%20Image%20Segmentation.pdf">[PDF]</a>
            <a href="https://mmcheng.net/del/">[Project Page]</a>
            <a href="https://github.com/yun-liu/del">[Code]</a>
            <a href="https://www.ijcai.org/proceedings/2018/120">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Crowd Counting with Deep Negative Correlation Learning</b><br>
            Zenglin Shi, Le Zhang, <strong>Yun Liu</strong>, XiaoFeng Cao, Yangdong Ye, Ming-Ming Cheng, and Guoyan Zheng<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018<br>
            <a href="https://yun-liu.github.io/papers/(CVPR'2018)Crowd%20Counting%20with%20Deep%20Negative%20Correlation%20Learning.pdf">[PDF]</a>
            <a href="https://sites.google.com/site/zhangleuestc/crowd-counting-with-deep-negative-learning/crowd-counting-with-deep-negative-learning">[Project Page]</a>
            <a href="https://github.com/shizenglin/Deep-NCL">[Code]</a>
            <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Crowd_Counting_via_CVPR_2018_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Direct Line Guidance Odometry</b><br>
            Shi-Jie Li, Bo Ren, <strong>Yun Liu</strong>, Ming-Ming Cheng, Duncan Frost, and Victor Prisacariu<br>
            <i>IEEE International Conference on Robotics and Automation (ICRA)</i>, 2018<br>
            <a href="https://yun-liu.github.io/papers/(ICRA'2018)Direct%20Line%20Guidance%20Odometry.pdf">[PDF]</a>
            <a href="https://ieeexplore.ieee.org/document/8461003">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Structure-measure: A New Way to Evaluate Foreground Maps</b><br>
            DengPing Fan, Ming-Ming Cheng, <strong>Yun Liu</strong>, Tao Li, and Ali Borji<br>
            <i>International Conference on Computer Vision (ICCV, <strong>Spotlight</strong>)</i>, 2017<br>
            <a href="https://yun-liu.github.io/papers/(ICCV'2017)Structure-measure%20-%20A%20New%20Way%20to%20Evaluate%20Foreground%20Maps.pdf">[PDF]</a>
            <a href="http://dpfan.net/smeasure/">[Project Page]</a>
            <a href="https://github.com/DengPingFan/S-measure">[Code]</a>
            <a href="https://yun-liu.github.io/materials/ICCV2017_S-measure_PPT.pdf">[PPT]</a>
            <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Structure-Measure_A_New_ICCV_2017_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Richer Convolutional Features for Edge Detection</b><br>
            <strong>Yun Liu</strong>, Ming-Ming Cheng, Xiaowei Hu, Kai Wang, and Xiang Bai<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2017<br>
            <a href="https://yun-liu.github.io/papers/(CVPR'2017)Richer%20Convolutional%20Features%20for%20Edge%20Detection.pdf">[PDF]</a>
            <a href="https://mmcheng.net/rcfedge/">[Project Page]</a>
            <a href="https://github.com/yun-liu/rcf">[Code]</a>
            <a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Liu_Richer_Convolutional_Features_CVPR_2017_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>HFS: Hierarchical Feature Selection for Efficient Image Segmentation</b><br>
            Ming-Ming Cheng<sup>#</sup>, <strong>Yun Liu<sup>#</sup></strong>, Qibin Hou, Jiawang Bian, Philip Torr, Shi-Min Hu, and Zhuowen Tu<br>
            <i>European Conference on Computer Vision (ECCV)</i>, 2016<br>
            <a href="https://yun-liu.github.io/papers/(ECCV'2016)HFS%20-%20Hierarchical%20Feature%20Selection%20for%20Efficient%20Image%20Segmentation.pdf">[PDF]</a>
            <a href="https://mmcheng.net/hfs/">[Project Page]</a>
            <a href="https://github.com/yun-liu/hfs">[Code]</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_53">[Official Version]</a>
          </p>
        </li>
      </ul>

      <div id="footer">
        <div id="footer-text"></div>
      </div>
      © Yun Liu

      <div class="container">
        <div style="display:inline-block;width:200px;">
          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5xe6txh5mnm&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
        </div>
      </div>

    </div>
  </body>
</html>
