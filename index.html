<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Deng-Ping Fan&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ethz2.png">
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Deng-Ping Fan</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:25px">
      <table>
        <tbody>
          <tr>
            <td width="670">
              <div id="toptitle">
                <h1>Deng-Ping Fan &nbsp; 范登平</h1>
              </div>
              <p>
                Deng-Ping Fan is a Postdoctoral Researcher, working with <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Prof. Luc Van Gool</a> in <a href="https://vision.ee.ethz.ch/">Computer Vision Lab</a> @ <a href="https://ethz.ch/en.html">ETH Zurich</a>.
                From 2019-2021, he was a research scientist (PI) and team lead of IIAI-CV&Med in <a href="http://www.inceptioniai.org/">IIAI</a>.
                He received his PhD. from Nankai University in 2019 under the supervision of <a href="https://mmcheng.net/cmm/">Prof. Ming-Ming Cheng</a>.
                His research interests includes computer vision, image processing, medical image analysis, <i>etc</i>.
              </p>
              <h3 style="padding-top:-5px"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:dengpfan@gmail.com">dengpfan@gmail.com</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=kakwJ5QAAAAJ&hl=zh-CN&oi=ao" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/DengPingFan" target="_blank">Github</a>
            </td>
            <td>
              <img src="./images/2-inch.jpg" border="0" width="120">
            </td>
          </tr>
        </tbody>
      </table>

      <!-- Activities -->
      <h2> Activities </h2>
      <ul>
        <li>
          <p>
            <b>Area Chair/Senior Programme Committee: </b>IJCAI 2021, MICCAI 2020 workshop (OMIA7)
            <br>
          </p>
        </li>
        <li>
          <p>
            <b>Conference Program Committee Board: </b>IJCAI (2022-2024)
            <br>
          </p>
        </li>  
        <li>
          <p>
            Conference Programme Committee: ICML 2022, ICLR 2022, CVPR 2019-2022, ICCV 2019、2021, ECCV 2020, AAAI 2018、2020-2022, <i>etc</i>. 
            <br>
          </p>
        </li>
        <li>
          <p>
            Journal Reviewer: IEEE TPAMI, IEEE TIP, IEEE TNNLS, IEEE TMM, IEEE TMI, IJCV, MIA, <i>etc</i>.
            <br>
          </p>
        </li>
        <li>
          <p>
            Memberships: Chinese Institute of Electronics (<a href="https://www.cie-info.org.cn/">CIE</a>) <a href="https://www.cie-info.org.cn/site/content/4286.html" style="color:#2E41DC;"><u>Senior Member</u></a>, <i>etc</i>.
            <br>
          </p>
        </li>
        <li>
          <p>
            Co-organize xxxx at ICCV 2021. [slides]
            <br>
          </p>
        </li>
      </ul>
      
      <!-- arXiv -->
      <h2> arXiv (*: Corresponding, ^Joint first authors)</h2>
      <ul>
        <li>
          <p>
            <b>Deep Facial Synthesis: A New Challenge</b><br>
            <strong>Deng-Ping Fan</strong>, Ziling Huang, Peng Zheng, Hong Liu*, Xuebin Qin*, Luc Van Gool<br>
            <i>arXiv</i>, 2021<br>
            <a href="https://arxiv.org/abs/2112.15439">[PDF]</a>
            <a href="https://github.com/DengPingFan/FSGAN">[Code]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Salient Objects in Clutter</b><br>
            <strong>Deng-Ping Fan</strong>, Jing Zhang, Gang Xu, Ming-Ming Cheng*, Ling Shao<br>
            <i>arXiv</i>, 2021<br>
            <a href="https://arxiv.org/abs/2105.03053">[PDF]</a>
            <a href="https://github.com/DengPingFan/SOC-DataAug">[Code]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Boundary-aware segmentation network for mobile and web applications</b><br>
            Xuebin Qin, <strong>Deng-Ping Fan*</strong>, Chenyang Huang, Cyril Diagne, Zichen Zhang, Adrià Cabeza Sant'Anna, Albert Suarez, Martin Jagersand, Ling Shao<br>
            <i>arXiv</i>, 2021<br>
            <a href="https://arxiv.org/abs/2101.04704">[PDF]</a>
            <a href="https://github.com/xuebinqin/BASNet">[Code]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Salient Object Detection via Integrity Learning</b><br>
            Mingchen Zhuge, <strong>Deng-Ping Fan</strong>, Nian Liu, Dingwen Zhang*, Dong Xu, Ling Shao<br>
            <i>arXiv</i>, 2021<br>
            <a href="https://arxiv.org/abs/2101.07663">[PDF]</a>
            <a href="https://github.com/mczhuge/ICON">[Code]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Weakly Supervised Visual-Auditory Saliency Detection with Multigranularity Perception</b><br>
            Guotao Wang, Chenglizhao Chen*, <strong>Deng-Ping Fan</strong>, Aimin Hao, Hong Qin<br>
            <i>arXiv</i>, 2021<br>
            <a href="https://arxiv.org/abs/2112.13697">[PDF]</a>
            <a href="https://github.com/guotaowang/STANet">[Code]</a>
          </p>
        </li>
      </ul>
      
      <!-- Journal papers -->
      <h2> Selected Journal Publications</h2>
      <ul>
        <li>
          <p>
            <b>Concealed Object Detection</b><br>
            <strong>Deng-Ping Fan</strong>, Ge-Peng Ji, Ming-Ming Cheng*, Ling Shao<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2022<br>
            <a href="https://arxiv.org/abs/2102.10274">[PDF]</a>
            <a href="https://github.com/GewelsJI/SINet-V2">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9444794">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Re-thinking co-salient object detection</b><br>
            <strong>Deng-Ping Fan</strong>, Tengpeng Li, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, Ming-Ming Cheng*, Huazhu Fu, Jianbing Shen<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2022<br>
            <a href="https://arxiv.org/abs/2007.03380v4">[PDF]</a>
            <a href="https://github.com/DengPingFan/CoEGNet?utm_source=catalyzex.com">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9358006">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Semantic Edge Detection with Diverse Deep Supervision</b><br>
            Yun Liu, Ming-Ming Cheng*, <strong>Deng-Ping Fan</strong>, Le Zhang, Jia-Wang Bian, and Dacheng Tao<br>
            <i>International Journal of Computer Vision (IJCV)</i>, 2022<br>
            <a href="https://yun-liu.github.io/papers/(IJCV'2021)Semantic%20Edge%20Detection%20with%20Diverse%20Deep%20Supervision.pdf">[PDF]</a>
            <a href="https://github.com/yun-liu/DDS">[Code]</a>
            <a href="https://link.springer.com/article/10.1007/s11263-021-01539-8">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Structure-measure: A new way to evaluate foreground maps</b><br>
            Ming-Ming Cheng*, <strong>Deng-Ping Fan</strong><br>
            <i>International Journal of Computer Vision (IJCV)</i>, 2021<br>
            [Extension of <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Structure-Measure_A_New_ICCV_2017_paper.html" style="color:#2E41DC;"><u>ICCV 2017</u></a>]<br>
            <a href="papers/[2022][IJCV]Structure-Measure A New WaytoEvaluateForegroundMaps.pdf">[PDF]</a>
            <a href="https://github.com/DengPingFan/S-measure">[Code]</a>
            <a href="https://link.springer.com/article/10.1007/s11263-021-01490-8">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Siamese Network for RGB-D Salient Object Detection and Beyond</b><br>
            Keren Fu, <strong>Deng-Ping Fan*</strong>, Ge-Peng Ji, Qijun Zhao, Jianbing Shen, Ce Zhu<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2008.12134">[PDF]</a>
            <a href="https://github.com/kerenfu/JLDCF/?utm_source=catalyzex.com">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9406382">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Uncertainty Inspired RGB-D Saliency Detection</b><br>
            Jing Zhang, <strong>Deng-Ping Fan*</strong>, Yuchao Dai, Saeed Anwar, Fatemeh Sadat Saleh, Sadegh Aliakbarian, Nick Barnes<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2009.03075">[PDF]</a>
            <a href="https://github.com/JingZhang617/UCNet?utm_source=catalyzex.com">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/9405467">[Official Version]</a>
          </p>
        </li>
        
        <li>
          <p>
            <b>Rethinking RGB-D Salient Object Detection: Models, Data Sets, and Large-Scale Benchmarks</b><br>
            <strong>Deng-Ping Fan</strong>, Zheng Lin, Zhao Zhang, Menglong Zhu, Ming-Ming Cheng*<br>
            <i>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</i>, 2021<br>
            <a href="https://arxiv.org/abs/1907.06781">[PDF]</a>
            <a href="https://github.com/DengPingFan/D3NetBenchmark">[Code/SIP Benchmark]</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/9107477">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>JCS: An Explainable COVID-19 Diagnosis System by Joint Classification and Segmentation</b><br>
            Yu-Huan Wu, Shang-Hua Gao, Jie Mei, Jun Xu, <strong>Deng-Ping Fan</strong>, Rong-Guo Zhang, Ming-Ming Cheng*<br>
            <i>IEEE Transactions on Image Processing (TIP)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2004.07054">[PDF]</a>
            <a href="https://github.com/yuhuan-wu/JCS">[Code]</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/9357961">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>COVID-19 Lung Infection Segmentation with A Novel Two-Stage Cross-Domain Transfer Learning Framework</b><br>
            Jiannan Liu, Bo Dong, Shuai Wang, Hui Cui, <strong>Deng-Ping Fan</strong>, Jiquan Ma*, Geng Chen*<br>
            <i>IEEE Transactions on Medical Imaging (MIA)</i>, 2021<br>
            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8342869/">[PDF]</a>
            <a href="https://github.com/Jiannan-Liu/nCoVSegNet">[Code]</a>
            <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002504?casa_token=4dIB3WQF8osAAAAA:WqK99Z08kXXrqrrX6DXK_6eWH_uX944wn_QaommMaJ45HItdj8Nc5EMS_DOUvjMTio476WmnLMI">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Inf-Net: Automatic Covid-19 Lung Infection Segmentation from CT Images</b><br>
            <strong>Deng-Ping Fan</strong>, Tao Zhou, Ge-Peng Ji, Yi Zhou, Geng Chen*, Huazhu Fu*, Jianbing Shen*, Ling Shao<br>
            <i>IEEE Transactions on Medical Imaging (TMI)</i>, 2020<br>
            [<strong><font color="red">ESI Highly Cited Paper</font></strong>, <a href="https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=42" style="color:#2E41DC;"><u>TMI 50 most frequently accessed articles</u></a>]
            <a href="">[PDF]</a>
            <a href="">[Code]</a>
            <a href="">[Official Version]</a>
          </p>
        </li>
        <!--
        <li>
          <p>
            <b>xxxx</b><br>
            xxxx<br>
            <i>xxxx</i>, xxxx<br>
            <a href="">[PDF]</a>
            <a href="">[Code]</a>
            <a href="">[Official Version]</a>
          </p>
        </li>
        </li>
        <li>
          <p>
            <b>xxxx</b><br>
            xxxx<br>
            <i>xxxx</i>, xxxx<br>
            <a href="">[PDF]</a>
            <a href="">[Code]</a>
            <a href="">[Official Version]</a>
          </p>
        </li> -->
      </ul>
      
      <!-- conference papers -->
      <h2> Selected Conference Publications</h2>
      <ul> 
        <li>
          <p>
            <b>Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions</b><br>
            Wenhai Wang, Enze Xie, Xiang Li, <strong>Deng-Ping Fan*</strong>, Kaitao Song, Ding Liang, Tong Lu*, Ping Luo, Ling Shao<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2021<br>
            [<strong><font color="red">Oral</font></strong>, Accept rate = 210/6236 = 3.4%]<br>
            <a href="https://arxiv.org/abs/2102.12122">[PDF]</a>
            <a href="https://github.com/whai362/PVT">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Pyramid_Vision_Transformer_A_Versatile_Backbone_for_Dense_Prediction_Without_ICCV_2021_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>RGB-D saliency detection via cascaded mutual information minimization</b><br>
            Jing Zhang, <strong>Deng-Ping Fan*</strong>, Yuchao Dai, Xin Yu, Yiran Zhong, Nick Barnes, Ling Shao<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2109.07246">[PDF]</a>
            <a href="https://github.com/JingZhang617/cascaded_rgbd_sod">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_RGB-D_Saliency_Detection_via_Cascaded_Mutual_Information_Minimization_ICCV_2021_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Specificity-preserving RGB-D Saliency Detection</b><br>
            Tao Zhou, <strong>Deng-Ping Fan*</strong>, Geng Chen, Yi Zhou, Huazhu Fu<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2108.08162">[PDF]</a>
            <a href="https://github.com/taozh2017/SPNet">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhou_Specificity-Preserving_RGB-D_Saliency_Detection_ICCV_2021_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Full-duplex strategy for video object segmentation</b><br>
            Ge-Peng Ji, <strong>Deng-Ping Fan*</strong>, Keren Fu, Zhe Wu, Jianbing Shen, Ling Shao<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2108.03151">[PDF]</a>
            <a href="https://github.com/GewelsJI/FSNet">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Ji_Full-Duplex_Strategy_for_Video_Object_Segmentation_ICCV_2021_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Kaleido-BERT: Vision-Language Pre-training on Fashion Domain</b><br>
            Mingchen Zhuge, Dehong Gao, <strong>Deng-Ping Fan*</strong>, Linbo Jin, Ben Chen, Haoming Zhou, Minghui Qiu, Ling Shao<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2103.16110">[PDF]</a>
            <a href="https://github.com/mczhuge/Kaleido-BERT">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhuge_Kaleido-BERT_Vision-Language_Pre-Training_on_Fashion_Domain_CVPR_2021_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Group Collaborative Learning for Co-Salient Object Detection</b><br>
            Qi Fan, <strong>Deng-Ping Fan*</strong>, Huazhu Fu, Chi-Keung Tang, Ling Shao, Yu-Wing Tai<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021<br>
            <a href="https://arxiv.org/abs/2104.01108">[PDF]</a>
            <a href="https://github.com/fanq15/GCoNet">[Code]</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Group_Collaborative_Learning_for_Co-Salient_Object_Detection_CVPR_2021_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Progressively Normalized Self-Attention Network for Video Polyp Segmentation</b><br>
            Ge-Peng Ji, Yu-Cheng Chou, <strong>Deng-Ping Fan*</strong>, Geng Chen, Huazhu Fu, Debesh Jha, Ling Shao<br>
            <i>Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2020<br>
            [<strong><font color="red">Early Accept & Student Travel Award</font></strong>, Accept rate = 13%]<br>
            <a href="https://arxiv.org/abs/2105.08468">[PDF]</a>
            <a href="https://github.com/GewelsJI/PNS-Net">[Code]</a>
            <a href="https://miccai2021.org/openaccess/paperlinks/2021/09/01/378-Paper0320.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>JL-DCF: Joint learning and densely-cooperative fusion framework for RGB-D salient object detection</b><br>
            Keren Fu, <strong>Deng-Ping Fan*</strong>, Ge-Peng Ji, Qijun Zhao<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2020<br>
            <a href="https://arxiv.org/abs/2004.08515">[PDF]</a>
            <a href="https://github.com/kerenfu/JLDCF/">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Fu_JL-DCF_Joint_Learning_and_Densely-Cooperative_Fusion_Framework_for_RGB-D_Salient_CVPR_2020_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>UC-Net: Uncertainty inspired rgb-d saliency detection via conditional variational autoencoders*</b><br>
            Jing Zhang, <strong>Deng-Ping Fan*</strong>, Yuchao Dai, Saeed Anwar, Fatemeh Sadat Saleh, Tong Zhang, Nick Barnes<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2020<br>
            [<strong><font color="red">Best Paper Nomination & Oral</font></strong>, Accept rate 0.44%]<br>
            <a href="https://arxiv.org/abs/2004.05763">[PDF]</a>
            <a href="https://github.com/JingZhang617/UCNet">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_UC-Net_Uncertainty_Inspired_RGB-D_Saliency_Detection_via_Conditional_Variational_Autoencoders_CVPR_2020_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>PraNet: Parallel reverse attention network for polyp segmentation</b><br>
            <strong>Deng-Ping Fan</strong>, Ge-Peng Ji, Tao Zhou, Geng Chen, Huazhu Fu*, Jianbing Shen*, Ling Shao<br>
            <i>Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2020<br>
            [<strong><font color="red">Oral & Early accept</font></strong>, Accept rate = 13%]<br>
            <a href="https://arxiv.org/abs/2006.11392">[PDF]</a>
            <a href="https://github.com/DengPingFan/PraNet">[Code]</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-59725-2_26">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>BBS-Net: RGB-D salient object detection with a bifurcated backbone strategy network</b><br>
            <strong>Deng-Ping Fan^</strong>, Yingjie Zhai^, Ali Borji, Jufeng Yang*, Ling Shao<br>
            <i>European Conference on Computer Vision (ECCV)</i>, 2020<br>
            <a href="https://arxiv.org/abs/2007.02713">[PDF]</a>
            <a href="https://github.com/zyjwuyan/BBS-Net">[Code]</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-58610-2_17">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Taking a deeper look at co-salient object detection</b><br>
            <strong>Deng-Ping Fan^</strong>, Zheng Lin^, Ge-Peng Ji, Dingwen Zhang, Huazhu Fu, Ming-Ming Cheng*<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2020<br>
            <a href="">[PDF]</a>
            <a href="">[CoSOD3K Benchmark]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Fan_Taking_a_Deeper_Look_at_Co-Salient_Object_Detection_CVPR_2020_paper.html">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Camouflaged object detection</b><br>
            <strong>Deng-Ping Fan</strong>, Ge-Peng Ji, Guolei Sun, Ming-Ming Cheng, Jianbing Shen*, Ling Shao<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2020<br>
            [<strong><font color="red">Oral</font></strong>, Accept rate = 335/5865 = 5.7%]<br>
            <a href="">[PDF]</a>
            <a href="https://github.com/DengPingFan/SINet/">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Fan_Camouflaged_Object_Detection_CVPR_2020_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Contrast Prior and Fluid Pyramid Integration for RGBD Salient Object Detection</b><br>
            Jia-Xing Zhao^, Yang Cao^, <strong>Deng-Ping Fan^</strong>, Ming-Ming Cheng*, Xuan-Yi Li, Le Zhang<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019<br>
            <a href="">[PDF]</a>
            <a href="https://mmcheng.net/rgbdsalpyr/">[Project Page]</a>
            <a href="https://github.com/JXingZhao/ContrastPrior">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Contrast_Prior_and_Fluid_Pyramid_Integration_for_RGBD_Salient_Object_CVPR_2019_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Shifting More Attention to Video Salient Object Detection</b><br>
            <strong>Deng-Ping Fan</strong>, Wenguan Wang, Ming-Ming Cheng*, Jianbing Shen<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019<br>
            [<strong><font color="red">Best Paper Finalist & Oral</font></strong>, Accept rate 0.87%]<br>
            <a href="">[PDF]</a>
            <a href="https://mmcheng.net/davsod/">[Project Page]</a>
            <a href="https://github.com/DengPingFan/DAVSOD">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Shifting_More_Attention_to_Video_Salient_Object_Detection_CVPR_2019_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Scoot: A Perceptual Metric for Facial Sketches</b><br>
            <strong>Deng-Ping Fan</strong>, ShengChuan Zhang, Yu-Huan Wu, Yun Liu, Ming-Ming Cheng*, Bo Ren, Paul Rosin, and Rongrong Ji<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2019<br>
            <a href="https://arxiv.org/abs/1908.08433.pdf">[PDF]</a>
            <a href="https://mmcheng.net/scoot/">[Project Page]</a>
            <a href="https://yun-liu.github.io/materials/ICCV2019_Scoot_Supplementary.pdf">[Supplementary Material]</a>
            <a href="https://github.com/DengPingFan/Scoot">[Code]</a>
            <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Fan_Scoot_A_Perceptual_Metric_for_Facial_Sketches_ICCV_2019_paper.html">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Enhanced-alignment measure for binary foreground map evaluation</b><br>
            <strong>Deng-Ping Fan</strong>, Cheng Gong, Yang Cao, Bo Ren*, Ming-Ming Cheng, Ali Borji<br>
            <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2018<br>
            [<strong><font color="red">IJCAI2018 <u><a href="https://www.paperdigest.org/2021/03/most-influential-ijcai-papers-2021-03/" style="color:#2E41DC;">Top-10</a></u> Influential Papers & Oral</strong></font> (Rate = 10/710 = 1.4%)]<br>
            <a href="https://arxiv.org/abs/1805.10421">[PDF]</a>
            <a href="https://github.com/DengPingFan/E-measure">[Code]</a>
            <a href="https://www.ijcai.org/proceedings/2018/97">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Salient objects in clutter: Bringing salient object detection to the foreground</b><br>
            <strong>Deng-Ping Fan</strong>, Ming-Ming Cheng*, Jiang-Jiang Liu, Shang-Hua Gao, Qibin Hou, Ali Borji<br>
            <i>European Conference on Computer Vision (ECCV)</i>, 2018<br>
            <a href="https://arxiv.org/abs/1803.06091">[PDF]</a>
            <a href="https://mmcheng.net/socbenchmark/">[Project Page]</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-01267-0_12">[Official Version]</a>
          </p>
        </li> 
        <li>
          <p>
            <b>Structure-measure: A New Way to Evaluate Foreground Maps</b><br>
            <strong>Deng-Ping Fan</strong>, Ming-Ming Cheng*, Jiang-Jiang Liu, Shang-Hua Gao, Qibin Hou, Ali Borji<br>
            <i>International Conference on Computer Vision (ICCV)</i>, 2017<br>
            [<strong><font color="red">Spotlight</font></strong>, Accept rate = 56/2143 = 2.6%]<br>
            <a href="https://yun-liu.github.io/papers/(ICCV'2017)Structure-measure%20-%20A%20New%20Way%20to%20Evaluate%20Foreground%20Maps.pdf">[PDF]</a>
            <a href="https://github.com/DengPingFan/S-measure">[Code]</a>
            <a href="https://yun-liu.github.io/materials/ICCV2017_S-measure_PPT.pdf">[PPT]</a>
            <a href="http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Structure-Measure_A_New_ICCV_2017_paper.html">[Official Version]</a>
          </p>
        </li> 
      </ul>
      
      <!-- Awards and Honors -->
      <h2> Awards and Honors </h2>
      <ul> 
        <li>
          <p>
            <b>Outstanding Doctoral Dissertation Award, China Computer Federation (CCF), 2021</b>
            <br>
          </p>
        </li>
        <li>
          <p>
            <b>CVPR Best Paper Nomination, 2020</b>
            <br>
          </p>
        </li>
        <li>
          <p>
            <b>CVPR Best Paper Finalist, 2019</b>
            <br>
          </p>
        </li>
        <li>
          <p>
            Outstanding Reviewer: CVPR 2019 with special mention (25/2887), CVPR 2020 (141/3664), CVPR 2021 (1065/5246), ECCV 2020
            <br>
          </p>
        </li>
        <li>
          <p>
            Outstanding PhD. Graduates in Nankai University, 2019
            <br>
          </p>
        </li>
        <li>
          <p>
            Huawei PhD. Fellowship, 2017
            <br>
          </p>
        </li>
      </ul>
      

      <div id="footer">
        <div id="footer-text"></div>
      </div>
      © Deng-Ping Fan

      <div class="container">
       
      </div>

    </div>
  </body>
</html>
